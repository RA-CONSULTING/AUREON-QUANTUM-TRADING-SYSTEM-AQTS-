
import { ElephantMemory } from '../core/elephantMemory';
import * as path from 'path';

class TargetPractice {
  private memory: ElephantMemory;
  private symbols = ['BTCUSDC', 'ETHUSDC', 'SOLUSDC', 'BNBUSDC', 'XRPUSDC', 'DOGEUSDC', 'ADAUSDC', 'AVAXUSDC', 'LINKUSDC', 'DOTUSDC', 'MATICUSDC', 'SHIBUSDC'];
  private feePercent = 0.001; // 0.1% per side
  
  constructor() {
    this.memory = new ElephantMemory();
  }

  private simulateTrade(symbol: string): SimulatedTrade {
    // Simulate price movement (Random walk with bias based on "memory"?)
    // For now, pure random walk with slight bullish bias for simulation
    const entryPrice = 100; // Normalized price
    let currentPrice = entryPrice;
    const volatility = 0.002; // 0.2% volatility
    
    // Simulate 60 seconds of price action
    for (let i = 0; i < 60; i++) {
        const change = (Math.random() - 0.48) * volatility * currentPrice; // Slight upward bias (0.48 instead of 0.5)
        currentPrice += change;
    }

    const exitPrice = currentPrice;
    const grossPnl = (exitPrice - entryPrice) / entryPrice;
    const fees = this.feePercent * 2;
    const netPnlPercent = grossPnl - fees;
    const netPnlUsd = netPnlPercent * 10; // Assuming $10 trade size

    return {
        symbol,
        entryPrice,
        exitPrice,
        netPnl: netPnlUsd,
        result: netPnlUsd > 0 ? 'WIN' : 'LOSS'
    };
  }

  async runSession(rounds: number = 50) {
    console.log('\n' + 'ğŸ˜'.repeat(60));
    console.log('  ğŸ¯ TARGET PRACTICE: ELEPHANT MEMORY TRAINING ğŸ¯');
    console.log('ğŸ˜'.repeat(60) + '\n');
    
    console.log(`ğŸ“š Loading Memory from: artifacts/elephant_memory.json`);
    console.log(`ğŸ¯ Target List: ${this.symbols.join(', ')}`);
    console.log(`ğŸ”„ Rounds: ${rounds}\n`);

    let totalWins = 0;
    let totalLosses = 0;
    let totalPnl = 0;

    for (let i = 1; i <= rounds; i++) {
        // 1. Select Target (Elephant prefers winners, avoids losers)
        // Simple selection for now: Random from list, but check if "avoid"
        let symbol = this.symbols[Math.floor(Math.random() * this.symbols.length)];
        
        // Check memory
        const stats = this.memory.getSymbolStats(symbol);
        if (this.memory.shouldAvoid(symbol)) {
            // console.log(`   âš ï¸  Skipping ${symbol} (Elephant remembers recent loss/cooldown)`);
            continue; 
        }

        // 2. Hunt
        this.memory.rememberHunt(symbol);
        
        // 3. Execute Simulation
        const trade = this.simulateTrade(symbol);
        
        // 4. Update Memory
        this.memory.rememberResult(symbol, { 
            trades: 1, 
            profit: trade.netPnl 
        });

        // Log
        const icon = trade.result === 'WIN' ? 'âœ…' : 'âŒ';
        console.log(`   ${icon} Round ${i}: ${symbol.padEnd(8)} | PnL: $${trade.netPnl.toFixed(4)} | Memory: ${stats?.wins || 0}W / ${stats?.losses || 0}L`);

        if (trade.result === 'WIN') totalWins++;
        else totalLosses++;
        totalPnl += trade.netPnl;
        
        await new Promise(r => setTimeout(r, 50)); // Fast simulation
    }

    console.log('\n' + 'â”€'.repeat(60));
    console.log('ğŸ“Š SESSION RESULTS');
    console.log('â”€'.repeat(60));
    console.log(`   ğŸ† Wins: ${totalWins}`);
    console.log(`   ğŸ’” Losses: ${totalLosses}`);
    console.log(`   ğŸ’° Net PnL: $${totalPnl.toFixed(4)}`);
    console.log('â”€'.repeat(60));
    
    console.log('\nğŸ˜ ELEPHANT MEMORY UPDATED.');
    console.log('   The system now knows which targets are profitable.');
    console.log('   "The Elephant never forgets."\n');
  }
}

const practice = new TargetPractice();
practice.runSession(100);


interface SimulatedTrade {
  symbol: string;
  entryPrice: number;
  exitPrice: number;
  netPnl: number;
  result: 'WIN' | 'LOSS';
}

class TargetPractice {
  private memory: ElephantMemory;
  private symbols = ['BTCUSDC', 'ETHUSDC', 'SOLUSDC', 'BNBUSDC', 'XRPUSDC', 'DOGEUSDC', 'ADAUSDC', 'AVAXUSDC', 'LINKUSDC', 'DOTUSDC', 'MATICUSDC', 'SHIBUSDC'];
  private feePercent = 0.001; // 0.1% per side
  
  constructor() {
    this.memory = new ElephantMemory();
  }

  private simulateTrade(symbol: string): SimulatedTrade {
    // Simulate price movement (Random walk with bias based on "memory"?)
    // For now, pure random walk with slight bullish bias for simulation
    const entryPrice = 100; // Normalized price
    let currentPrice = entryPrice;
    const volatility = 0.002; // 0.2% volatility
    
    // Simulate 60 seconds of price action
    for (let i = 0; i < 60; i++) {
        const change = (Math.random() - 0.48) * volatility * currentPrice; // Slight upward bias (0.48 instead of 0.5)
        currentPrice += change;
    }

    const exitPrice = currentPrice;
    const grossPnl = (exitPrice - entryPrice) / entryPrice;
    const fees = this.feePercent * 2;
    const netPnlPercent = grossPnl - fees;
    const netPnlUsd = netPnlPercent * 10; // Assuming $10 trade size

    return {
        symbol,
        entryPrice,
        exitPrice,
        netPnl: netPnlUsd,
        result: netPnlUsd > 0 ? 'WIN' : 'LOSS'
    };
  }

  async runSession(rounds: number = 50) {
    console.log('\n' + 'ğŸ˜'.repeat(60));
    console.log('  ğŸ¯ TARGET PRACTICE: ELEPHANT MEMORY TRAINING ğŸ¯');
    console.log('ğŸ˜'.repeat(60) + '\n');
    
    console.log(`ğŸ“š Loading Memory from: artifacts/elephant_memory.json`);
    console.log(`ğŸ¯ Target List: ${this.symbols.join(', ')}`);
    console.log(`ğŸ”„ Rounds: ${rounds}\n`);

    let totalWins = 0;
    let totalLosses = 0;
    let totalPnl = 0;

    for (let i = 1; i <= rounds; i++) {
        // 1. Select Target (Elephant prefers winners, avoids losers)
        // Simple selection for now: Random from list, but check if "avoid"
        let symbol = this.symbols[Math.floor(Math.random() * this.symbols.length)];
        
        // Check memory
        const stats = this.memory.getSymbolStats(symbol);
        if (this.memory.shouldAvoid(symbol)) {
            // console.log(`   âš ï¸  Skipping ${symbol} (Elephant remembers recent loss/cooldown)`);
            continue; 
        }

        // 2. Hunt
        this.memory.rememberHunt(symbol);
        
        // 3. Execute Simulation
        const trade = this.simulateTrade(symbol);
        
        // 4. Update Memory
        this.memory.rememberResult(symbol, { 
            trades: 1, 
            profit: trade.netPnl 
        });

        // Log
        const icon = trade.result === 'WIN' ? 'âœ…' : 'âŒ';
        console.log(`   ${icon} Round ${i}: ${symbol.padEnd(8)} | PnL: $${trade.netPnl.toFixed(4)} | Memory: ${stats?.wins || 0}W / ${stats?.losses || 0}L`);

        if (trade.result === 'WIN') totalWins++;
        else totalLosses++;
        totalPnl += trade.netPnl;
        
        await new Promise(r => setTimeout(r, 50)); // Fast simulation
    }

    console.log('\n' + 'â”€'.repeat(60));
    console.log('ğŸ“Š SESSION RESULTS');
    console.log('â”€'.repeat(60));
    console.log(`   ğŸ† Wins: ${totalWins}`);
    console.log(`   ğŸ’” Losses: ${totalLosses}`);
    console.log(`   ğŸ’° Net PnL: $${totalPnl.toFixed(4)}`);
    console.log('â”€'.repeat(60));
    
    console.log('\nğŸ˜ ELEPHANT MEMORY UPDATED.');
    console.log('   The system now knows which targets are profitable.');
    console.log('   "The Elephant never forgets."\n');
  }
}

const practice = new TargetPractice();
practice.runSession(100);
